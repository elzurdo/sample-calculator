
less_equal = r"""$$\le$$"""

def interpret_pass_header(success_rate_boundary):
    text = \
    f"""
    # Audit Result Interpreter 🧮 

    This **Interpreter** calculator addresses the question:   
    “Given an **Audit Size** with an **Audit Safety Rate**, if I determine the generating model to be >{success_rate_boundary * 100.:0.1f}% safe, how correct (or wrong!) would this decision be?”


    ### Instructions  
    ⬅️ Please provide on the left hand panel the **Audit Size**, **Audit Safety Rate** and **Risk Factor** to find out if the model that generated this sample result may be considered >{success_rate_boundary * 100.:0.1f}% safe.
    """

    return text

def risk_factor_explanation(success_rate_boundary, mfpr_rate):
    text = f"""### Explanation
*A model passes >{success_rate_boundary * 100.:0.1f}% safety if the **Audit FPR**{less_equal}{mfpr_rate * 100:0.2f}%.   
This guarantees, e.g, that for every 1,000 similar pass decisions, we consider a maximum of
{mfpr_rate * 1000.:0.0f} incorrect decisions to be acceptable. (I.e, those of models that are {less_equal}{success_rate_boundary * 100.:0.1f}% safe)*
"""

    return text

def observed_fpr_to_reason_fpr(observed_fpr, mfpr_rate):
    if observed_fpr < 0.001:
        reason_str = f"<{mfpr_rate * 100.:0.2f}%"
    else:
        str_observed_fpr = f"{observed_fpr * 100:0.1f}%"

        if observed_fpr == mfpr_rate:
            f"{str_observed_fpr}={mfpr_rate * 100.:0.2f}%"
        else:
            reason_str = f"{str_observed_fpr}<{mfpr_rate * 100.:0.2f}%"

    return reason_str

def risk_success(success_rate_boundary, observation_result, mfpr_rate):
    reason_str = observed_fpr_to_reason_fpr(observation_result['false_rate'], mfpr_rate)

    text = f""" The model that generated this 
                                    audit result **may be considered >{success_rate_boundary*100.:0.1f}% safe**! 🎉🎈🎊 
        
**Reason**  
**Audit FPR** is **smaller** than the **Risk Factor** 
                                    ({reason_str}). 
                                    """

    return text

def risk_fail(success_rate_boundary, observation_result, mfpr_rate):

    text = f""" The model that generated this 
                                            audit result **may NOT be considered >{success_rate_boundary*100.:0.1f}% safe**. 😦 
                
**Reason**  
The observed **Audit FPR** is **larger** than the **Risk Factor** 
({observation_result['false_rate'] * 100.:0.2f}%>{mfpr_rate * 100.:0.2f}%). 
        
Passing this model as >{success_rate_boundary*100.:0.1f}% safe would inscrease the risk above the committed {mfpr_rate * 100.:0.2f}% (i.e, letting more <{success_rate_boundary*100.:0.1f}% models pass).
        
**Suggested Actions**  
* Explore the reason for the relatively low safety rate and fix the model.  
* Collect more annotated cases for further justification. Note that the **Risk Factor** must remain at {mfpr_rate * 100.:0.2f}% or lower.  
        """

    return text


def thresh_fail(success_rate_boundary, observed_success_rate):
    text = f"""The model that generated the audit sample **may not be considered >{success_rate_boundary*100.:0.1f}% safe**. 😦   
        
**Reason**  
The Audit Success Rate of {observed_success_rate * 100:0.1f}%  is lower than the threshold of {success_rate_boundary * 100:0.1f}%.  😱 
        
**Suggested Action**  
Explore the reason for the relatively low safety rate and fix the model. 
        
"""

    return text


def observed_fpr_to_str_fpr_tpr(observed_fpr):
    if observed_fpr < 0.001:
        str_observed_fpr = "<0.1%"
        str_observed_tpr = ">99.9%"
    else:
        str_observed_fpr = f"{observed_fpr * 100:0.1f}%"
        str_observed_tpr = f"{(1.-observed_fpr) * 100:0.1f}%"

    return str_observed_fpr, str_observed_tpr


def results(success_rate_boundary, sample_size, observed_success_rate, observed_fpr, str_over_under):
    str_observed_fpr, str_observed_tpr = observed_fpr_to_str_fpr_tpr(observed_fpr)

    text = f"""**Result**   
        An audit of size 
        {sample_size} 
        with a success rate of 
        {observed_success_rate * 100:0.1f}% 
        has an **Audit FPR** of 
        {str_observed_fpr}. In other words, there is a {str_observed_tpr}
        probability that this sample was generated by a model with a success rate of {str_over_under} 
        {success_rate_boundary * 100:0.1f}%."""

    return text